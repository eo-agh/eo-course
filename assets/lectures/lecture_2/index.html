
<!doctype html>
<html lang="en" class="no-js">
  <head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      
      
      
      
        <link rel="prev" href="../lecture_1/">
      
      
        <link rel="next" href="../lecture_3/">
      
      
      <link rel="icon" href="../../images/favicon.png">
      <meta name="generator" content="mkdocs-1.6.1, mkdocs-material-9.6.12">
    
    
      
        <title>Lecture 2 - Remote Sensing and Image Analysis in Space Tech</title>
      
    
    
      <link rel="stylesheet" href="../../stylesheets/main.2afb09e1.min.css">
      
        
        <link rel="stylesheet" href="../../stylesheets/palette.06af60db.min.css">
      
      


    
    
      
    
    
      
        
        
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto:300,300i,400,400i,700,700i%7CRoboto+Mono:400,400i,700,700i&display=fallback">
        <style>:root{--md-text-font:"Roboto";--md-code-font:"Roboto Mono"}</style>
      
    
    
    <script>__md_scope=new URL("../../..",location),__md_hash=e=>[...e].reduce(((e,_)=>(e<<5)-e+_.charCodeAt(0)),0),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script>
    
      

    
    
    
  </head>
  
  
    
    
      
    
    
    
    
    <body dir="ltr" data-md-color-scheme="default" data-md-color-primary="indigo" data-md-color-accent="indigo">
  
    
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" for="__drawer"></label>
    <div data-md-component="skip">
      
        
        <a href="#lecture-2-remote-sensing-analysis-applications" class="md-skip">
          Skip to content
        </a>
      
    </div>
    <div data-md-component="announce">
      
    </div>
    
    
      

  

<header class="md-header md-header--shadow" data-md-component="header">
  <nav class="md-header__inner md-grid" aria-label="Header">
    <a href="../../.." title="Remote Sensing and Image Analysis in Space Tech" class="md-header__button md-logo" aria-label="Remote Sensing and Image Analysis in Space Tech" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54"/></svg>

    </a>
    <label class="md-header__button md-icon" for="__drawer">
      
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M3 6h18v2H3zm0 5h18v2H3zm0 5h18v2H3z"/></svg>
    </label>
    <div class="md-header__title" data-md-component="header-title">
      <div class="md-header__ellipsis">
        <div class="md-header__topic">
          <span class="md-ellipsis">
            Remote Sensing and Image Analysis in Space Tech
          </span>
        </div>
        <div class="md-header__topic" data-md-component="header-topic">
          <span class="md-ellipsis">
            
              Lecture 2
            
          </span>
        </div>
      </div>
    </div>
    
      
        <form class="md-header__option" data-md-component="palette">
  
    
    
    
    <input class="md-option" data-md-color-media="(prefers-color-scheme)" data-md-color-scheme="default" data-md-color-primary="indigo" data-md-color-accent="indigo"  aria-label="Switch to light mode"  type="radio" name="__palette" id="__palette_0">
    
      <label class="md-header__button md-icon" title="Switch to light mode" for="__palette_1" hidden>
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M3.9 12c0-1.71 1.39-3.1 3.1-3.1h4V7H7a5 5 0 0 0-5 5 5 5 0 0 0 5 5h4v-1.9H7c-1.71 0-3.1-1.39-3.1-3.1M8 13h8v-2H8zm9-6h-4v1.9h4c1.71 0 3.1 1.39 3.1 3.1s-1.39 3.1-3.1 3.1h-4V17h4a5 5 0 0 0 5-5 5 5 0 0 0-5-5"/></svg>
      </label>
    
  
    
    
    
    <input class="md-option" data-md-color-media="(prefers-color-scheme: light)" data-md-color-scheme="default" data-md-color-primary="indigo" data-md-color-accent="indigo"  aria-label="Switch to dark mode"  type="radio" name="__palette" id="__palette_1">
    
      <label class="md-header__button md-icon" title="Switch to dark mode" for="__palette_2" hidden>
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M17 7H7a5 5 0 0 0-5 5 5 5 0 0 0 5 5h10a5 5 0 0 0 5-5 5 5 0 0 0-5-5m0 8a3 3 0 0 1-3-3 3 3 0 0 1 3-3 3 3 0 0 1 3 3 3 3 0 0 1-3 3"/></svg>
      </label>
    
  
    
    
    
    <input class="md-option" data-md-color-media="(prefers-color-scheme: dark)" data-md-color-scheme="slate" data-md-color-primary="black" data-md-color-accent="indigo"  aria-label="Switch to system preference"  type="radio" name="__palette" id="__palette_2">
    
      <label class="md-header__button md-icon" title="Switch to system preference" for="__palette_0" hidden>
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M17 7H7a5 5 0 0 0-5 5 5 5 0 0 0 5 5h10a5 5 0 0 0 5-5 5 5 0 0 0-5-5M7 15a3 3 0 0 1-3-3 3 3 0 0 1 3-3 3 3 0 0 1 3 3 3 3 0 0 1-3 3"/></svg>
      </label>
    
  
</form>
      
    
    
      <script>var palette=__md_get("__palette");if(palette&&palette.color){if("(prefers-color-scheme)"===palette.color.media){var media=matchMedia("(prefers-color-scheme: light)"),input=document.querySelector(media.matches?"[data-md-color-media='(prefers-color-scheme: light)']":"[data-md-color-media='(prefers-color-scheme: dark)']");palette.color.media=input.getAttribute("data-md-color-media"),palette.color.scheme=input.getAttribute("data-md-color-scheme"),palette.color.primary=input.getAttribute("data-md-color-primary"),palette.color.accent=input.getAttribute("data-md-color-accent")}for(var[key,value]of Object.entries(palette.color))document.body.setAttribute("data-md-color-"+key,value)}</script>
    
    
    
      
      
        <label class="md-header__button md-icon" for="__search">
          
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg>
        </label>
        <div class="md-search" data-md-component="search" role="dialog">
  <label class="md-search__overlay" for="__search"></label>
  <div class="md-search__inner" role="search">
    <form class="md-search__form" name="search">
      <input type="text" class="md-search__input" name="query" aria-label="Search" placeholder="Search" autocapitalize="off" autocorrect="off" autocomplete="off" spellcheck="false" data-md-component="search-query" required>
      <label class="md-search__icon md-icon" for="__search">
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg>
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11z"/></svg>
      </label>
      <nav class="md-search__options" aria-label="Search">
        
        <button type="reset" class="md-search__icon md-icon" title="Clear" aria-label="Clear" tabindex="-1">
          
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12z"/></svg>
        </button>
      </nav>
      
    </form>
    <div class="md-search__output">
      <div class="md-search__scrollwrap" tabindex="0" data-md-scrollfix>
        <div class="md-search-result" data-md-component="search-result">
          <div class="md-search-result__meta">
            Initializing search
          </div>
          <ol class="md-search-result__list" role="presentation"></ol>
        </div>
      </div>
    </div>
  </div>
</div>
      
    
    
      <div class="md-header__source">
        <a href="https://github.com/eo-agh/eo-labs/" title="Go to repository" class="md-source" data-md-component="source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><!--! Font Awesome Free 6.7.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M439.55 236.05 244 40.45a28.87 28.87 0 0 0-40.81 0l-40.66 40.63 51.52 51.52c27.06-9.14 52.68 16.77 43.39 43.68l49.66 49.66c34.23-11.8 61.18 31 35.47 56.69-26.49 26.49-70.21-2.87-56-37.34L240.22 199v121.85c25.3 12.54 22.26 41.85 9.08 55a34.34 34.34 0 0 1-48.55 0c-17.57-17.6-11.07-46.91 11.25-56v-123c-20.8-8.51-24.6-30.74-18.64-45L142.57 101 8.45 235.14a28.86 28.86 0 0 0 0 40.81l195.61 195.6a28.86 28.86 0 0 0 40.8 0l194.69-194.69a28.86 28.86 0 0 0 0-40.81"/></svg>
  </div>
  <div class="md-source__repository">
    GitHub
  </div>
</a>
      </div>
    
  </nav>
  
</header>
    
    <div class="md-container" data-md-component="container">
      
      
        
          
        
      
      <main class="md-main" data-md-component="main">
        <div class="md-main__inner md-grid">
          
            
              
              <div class="md-sidebar md-sidebar--primary" data-md-component="sidebar" data-md-type="navigation" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    



<nav class="md-nav md-nav--primary" aria-label="Navigation" data-md-level="0">
  <label class="md-nav__title" for="__drawer">
    <a href="../../.." title="Remote Sensing and Image Analysis in Space Tech" class="md-nav__button md-logo" aria-label="Remote Sensing and Image Analysis in Space Tech" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54"/></svg>

    </a>
    Remote Sensing and Image Analysis in Space Tech
  </label>
  
    <div class="md-nav__source">
      <a href="https://github.com/eo-agh/eo-labs/" title="Go to repository" class="md-source" data-md-component="source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><!--! Font Awesome Free 6.7.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M439.55 236.05 244 40.45a28.87 28.87 0 0 0-40.81 0l-40.66 40.63 51.52 51.52c27.06-9.14 52.68 16.77 43.39 43.68l49.66 49.66c34.23-11.8 61.18 31 35.47 56.69-26.49 26.49-70.21-2.87-56-37.34L240.22 199v121.85c25.3 12.54 22.26 41.85 9.08 55a34.34 34.34 0 0 1-48.55 0c-17.57-17.6-11.07-46.91 11.25-56v-123c-20.8-8.51-24.6-30.74-18.64-45L142.57 101 8.45 235.14a28.86 28.86 0 0 0 0 40.81l195.61 195.6a28.86 28.86 0 0 0 40.8 0l194.69-194.69a28.86 28.86 0 0 0 0-40.81"/></svg>
  </div>
  <div class="md-source__repository">
    GitHub
  </div>
</a>
    </div>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../introduction/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Introduction
    
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../projects/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Semester projects
    
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_3" >
        
          
          <label class="md-nav__link" for="__nav_3" id="__nav_3_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    Labs
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_3_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_3">
            <span class="md-nav__icon md-icon"></span>
            Labs
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../labs/lab_0/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Lab 0
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../labs/lab_1.md" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Lab 1
    
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
    
  
  
  
    
    
    
    
    
    <li class="md-nav__item md-nav__item--active md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_4" checked>
        
          
          <label class="md-nav__link" for="__nav_4" id="__nav_4_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    Lectures
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_4_label" aria-expanded="true">
          <label class="md-nav__title" for="__nav_4">
            <span class="md-nav__icon md-icon"></span>
            Lectures
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../lecture_1/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Lecture 1
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
    
  
  
  
    <li class="md-nav__item md-nav__item--active">
      
      <input class="md-nav__toggle md-toggle" type="checkbox" id="__toc">
      
      
        
      
      
        <label class="md-nav__link md-nav__link--active" for="__toc">
          
  
  
  <span class="md-ellipsis">
    Lecture 2
    
  </span>
  

          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <a href="./" class="md-nav__link md-nav__link--active">
        
  
  
  <span class="md-ellipsis">
    Lecture 2
    
  </span>
  

      </a>
      
        

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#learning-objectives" class="md-nav__link">
    <span class="md-ellipsis">
      🎯 Learning Objectives
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#lecture-topics-overview" class="md-nav__link">
    <span class="md-ellipsis">
      📌 Lecture Topics Overview
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#1-creating-satellite-imagery" class="md-nav__link">
    <span class="md-ellipsis">
      1. Creating Satellite Imagery
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#11-single-channel-imagery" class="md-nav__link">
    <span class="md-ellipsis">
      1.1 Single Channel Imagery
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#12-true-color-imagery" class="md-nav__link">
    <span class="md-ellipsis">
      1.2 True Color Imagery
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#13-false-color-imagery" class="md-nav__link">
    <span class="md-ellipsis">
      1.3 False Color Imagery
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#2-spectral-indices" class="md-nav__link">
    <span class="md-ellipsis">
      2. Spectral Indices
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#21-deep-dive-into-spectral-indices" class="md-nav__link">
    <span class="md-ellipsis">
      2.1 Deep dive into Spectral Indices
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#211-what-is-ndvi" class="md-nav__link">
    <span class="md-ellipsis">
      2.1.1 What is NDVI?
    </span>
  </a>
  
</li>
      
    </ul>
  
</nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../lecture_3/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Lecture 3
    
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../contact/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Contact
    
  </span>
  

      </a>
    </li>
  

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
              
              <div class="md-sidebar md-sidebar--secondary" data-md-component="sidebar" data-md-type="toc" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#learning-objectives" class="md-nav__link">
    <span class="md-ellipsis">
      🎯 Learning Objectives
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#lecture-topics-overview" class="md-nav__link">
    <span class="md-ellipsis">
      📌 Lecture Topics Overview
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#1-creating-satellite-imagery" class="md-nav__link">
    <span class="md-ellipsis">
      1. Creating Satellite Imagery
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#11-single-channel-imagery" class="md-nav__link">
    <span class="md-ellipsis">
      1.1 Single Channel Imagery
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#12-true-color-imagery" class="md-nav__link">
    <span class="md-ellipsis">
      1.2 True Color Imagery
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#13-false-color-imagery" class="md-nav__link">
    <span class="md-ellipsis">
      1.3 False Color Imagery
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#2-spectral-indices" class="md-nav__link">
    <span class="md-ellipsis">
      2. Spectral Indices
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#21-deep-dive-into-spectral-indices" class="md-nav__link">
    <span class="md-ellipsis">
      2.1 Deep dive into Spectral Indices
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#211-what-is-ndvi" class="md-nav__link">
    <span class="md-ellipsis">
      2.1.1 What is NDVI?
    </span>
  </a>
  
</li>
      
    </ul>
  
</nav>
                  </div>
                </div>
              </div>
            
          
          
            <div class="md-content" data-md-component="content">
              <article class="md-content__inner md-typeset">
                
                  


  
  


<h1 id="lecture-2-remote-sensing-analysis-applications">🛰️ Lecture 2: Remote Sensing Analysis &amp; Applications</h1>
<hr />
<h2 id="learning-objectives">🎯 Learning Objectives</h2>
<p>By the end of this lecture, you will understand:</p>
<ul>
<li><strong>How to create satellite imagery</strong>, by mapping quantative sensor data to a range of colors for qualitative visual analysis.</li>
<li><strong>What are spectral indices</strong>, including NDVI and other vegetation indices, and their importance in environmental monitoring.</li>
<li><strong>Principles and methods of image classification</strong>, including supervised and unsupervised approaches.</li>
<li><strong>How to preprocess remote sensing data</strong>, including atmospheric and geometric corrections.</li>
<li><strong>Common applications of remote sensing across various sectors</strong> (e.g., agriculture, urban mapping, disaster management).</li>
<li><strong>Validation and accuracy assessment of remote sensing analysis</strong>.</li>
</ul>
<hr />
<h2 id="lecture-topics-overview">📌 Lecture Topics Overview</h2>
<ol>
<li><strong>Band compositions</strong></li>
<li><strong>Spectral Indices</strong>  </li>
<li><strong>Image Classification Techniques</strong>  </li>
<li><strong>Applications of Remote Sensing</strong>  </li>
<li><strong>Accuracy Assessment and Validation</strong>  </li>
</ol>
<h2 id="1-creating-satellite-imagery">1. Creating Satellite Imagery</h2>
<p>When we combine data collected by remote sensors with our knowledge of the observed target’s spectral signatures, we can learn about many geophysical parameters, which are the properties and characteristics of different parts of the Earth system. In this lesson, you’ll learn about using satellite imagery to visualize this information, and about how data products at different processing levels allow you to analyze it quantitatively. You will also explore case studies where these techniques are applied to address real-world problems. You will then be able to answer the question, HOW CAN I USE REMOTE SENSING DATA?</p>
<p>Example (below): This Advanced Spaceborne Thermal Emission and Reflection Radiometer (ASTER) image from August 14, 2002, combines visible and infrared bands to show the Biscuit Fire in the Northwest U.S., with active fire areas in red coloring. Credit: NASA/METI/AIST/Japan Space Systems, and U.S./Japan ASTER Science Team</p>
<p><img alt="Remote Sensing Example 1" src="https://raw.githubusercontent.com/eo-agh/eo-course/main/docs/assets/images/lecture2_image1.jpg" />  </p>
<p><strong>The remotely sensed data from satellite sensors is typically visualized with satellite imagery.</strong> This imagery can represent one channel or a combination of several channels from the sensor. While the satellite sensor data itself is <strong>quantitative</strong>, the imagery is created by mapping this data to a range of colors for <strong>qualitative visual analysis</strong>.</p>
<p><img alt="Remote Sensing Example 2" src="https://raw.githubusercontent.com/eo-agh/eo-course/main/docs/assets/images/lecture2_image2.jpg" />  </p>
<h2 id="11-single-channel-imagery">1.1 Single Channel Imagery</h2>
<p>For each single band, satellite remote sensors directly measure radiance, which is the intensity of radiation in a given direction. Radiance is often quantified using a Brightness Temperature scale, expressed in degrees Celsius. The GOES "Clean Infrared" channel (or Band 13) is shown here as an example, and a color bar is applied to the data in order to highlight the cloud top surfaces with the lowest thermal temperatures. The red to magenta color range corresponds to the coldest cloud tops and strongest convection. Note also the warm cloud, land, and water surfaces that are less prominent in the light gray shades, and a different color curve could be used instead to highlight these warm features in this same scene. This single band can be used for analysis on its own, or combined with other bands in more complex imagery.</p>
<p><img alt="Remote Sensing Example 3" src="https://raw.githubusercontent.com/eo-agh/eo-course/main/docs/assets/images/lecture2_image3.png" />  </p>
<p>"Clean Infrared" Band 13 from GOES Advanced Baseline Imager (ABI) centered over Colombia South America for 17 July 2024 at 1800 UTC. A color curve is applied to the Brightness Temperature data where warm features are in light gray shades and cold features are in red to black to gray to magenta shades. Source: NASA Worldview</p>
<p>Given measurements of radiance, the ratio of the radiation striking a surface to the radiation reflected off can then be calculated, and this is referred to as reflectance. The same scene from GOES ABI is shown here but for the "Red Visible" Band 2 as single channel imagery. The reflectance is displayed on a black to white scale with the highest values in white to correspond with cloud features. Note how the cold clouds are less obvious compared to the prior Clean Infrared imagery, but the presence of all clouds is much easier to analyze, particularly over the water/ocean area on the left side of the imagery. One way that scientists create more complex satellite imagery is to combine reflectances from multiple bands.</p>
<p><img alt="Remote Sensing Example 4" src="https://raw.githubusercontent.com/eo-agh/eo-course/main/docs/assets/images/lecture2_image4.jpg" /><br />
"Red Visible" Band 2 from GOES Advanced Baseline Imager (ABI) centered over Colombia South America for 17 July 2024 at 1800 UTC (same as above image of "Clean Infrared"). A black to white scale is applied with the largest reflectance values in white. Source: NASA Worldview</p>
<h2 id="12-true-color-imagery">1.2 True Color Imagery</h2>
<p>🎯 <strong>True Color</strong> imagery was designed to display the Earth in colors similar to what we might see with our own eyes. The product is primarily a combination of available channels that are sensitive to the red, green, and blue visible light. The image below shows how the VIIRS instrument's visible red, green and blue bands are combined to generate the composite true color image (i.e., a Red-Green-Blue, or RGB imagery product).</p>
<p>In the graphic below, the VIIRS images from each channel (red, green, and blue) show reflectances from these bands in a black to white scale. Each single channel image looks similar, but they have important differences. For example, in the red image, the water is darker, and the scene is slightly dimmer. The blue is lighter because it's shorter wavelengths are more easily scattered by the atmosphere. The values that represent the cloudy areas are very similar because reflectance by clouds doesn’t depend very much on wavelength. However you can see the red and green bands are more absorbed (i.e., appear darker) by the water than the blue band. When the three visible channels are combined (i.e., an RGB product), you can now make out bare soil and brown colors. The water looks bluer, and the clouds still appear white.</p>
<p><img alt="Remote Sensing Example 5" src="https://raw.githubusercontent.com/eo-agh/eo-course/main/docs/assets/images/lecture2_image5.jpg" /><br />
S-NPP VIIRS instrument combination of visible wavelengths resulting in a True Color image as your eye would see from space. Source: NASA</p>
<h2 id="13-false-color-imagery">1.3 False Color Imagery</h2>
<p>While true color images are created by assigning the red, green, and blue colors to the red, green, and blue visible wavelengths, respectively, false color images are created by assigning different wavelengths to one or more colors. For example, we can use color to depict non-visible wavelengths, such as infrared or ultraviolet which may be associated with things like atmospheric gases and heat, to create an enhanced image for analysis. This is why the image colors may not correspond to what we expect to see.</p>
<p><img alt="Remote Sensing Example 6" src="https://raw.githubusercontent.com/eo-agh/eo-course/main/docs/assets/images/lecture2_image6.jpg" /><br />
Landsat Imagery Comparison of a Wildfire Scene: True Color RGB (left), False Color RGB (right). Source: NASA</p>
<p>The image on the left is the visible true color image of a wildfire. Smoke is obscuring the burned area. RGB Imagery Color Components to Wavelengths: Red = 0.66 µm, Green = 0.55 µm, Blue = 0.47 µm.</p>
<p>To "see through” the smoke, we can use the shortwave infrared (SWIR) and near-infrared (NIR) channels. In the false color image on the right for the same fire event, the areas in purple coloring stands out and represents land that has been burned. Even though we can see through the smoke, you can still see shades of smoke in the right image as dark smudges. Image Color to Wavelength: Red = 1.6 µm (Shortwave Infrared), Green = 1.2 µm (Near-Infrared), Blue = 2.1 µm (Shortwave Infrared).</p>
<p>Alternatively, when using an RGB imagery product, each pixel contains a red, green, and blue color component toward the final pixel color. A satellite band or band difference is used within each color component of the RGB in order to identify multiple geophysical parameters within one image (i.e., cloud thickness, phase, and height all within the same image).</p>
<p><img alt="Remote Sensing Example 7" src="https://raw.githubusercontent.com/eo-agh/eo-course/main/docs/assets/images/lecture2_image7.png" /><br />
Source: Himawari-8 AHI</p>
<p>Then, the geophysical parameter range is scaled between black (i.e., no color) to the maximum color intensity per RGB component (i.e., full red, full green, or full blue).</p>
<p><img alt="Remote Sensing Example 8" src="https://raw.githubusercontent.com/eo-agh/eo-course/main/docs/assets/images/lecture2_image8.png" /><br />
Source: Himawari-8 AHI</p>
<h2 id="2-spectral-indices">2. Spectral Indices</h2>
<p>📌 <strong>What is a spectral index?</strong></p>
<ul>
<li>A mathematical equation that is applied on the various spectral bands of an image per pixel</li>
<li>Simple band ratios that highlight a specific process or property on the land surface</li>
<li>Reduce effects of atmosphere, instrument noise, sun angle: allows for consistent spatial and temporal comparisons</li>
</ul>
<p>🎯 Spectral indices are used to enhance particular land surface features or properties, e.g. vegetation, soil, water. There are developed based on the spectral properties of the object of interest.</p>
<p><strong>Applications of Spectral Indices include, e.g.:</strong></p>
<ul>
<li>Vegetation Health</li>
<li>Burned Area Mapping and Fire Severity</li>
<li>Water Content</li>
<li>Biophysical Parameters (i.e., biomass)</li>
<li>Geologic Mapping </li>
</ul>
<p><img alt="Spectral Indice Example 1" src="https://raw.githubusercontent.com/eo-agh/eo-course/main/docs/assets/images/lecture2_image11.png" />  </p>
<p>By examining the spectral curves of various objects, one can detect unique variations in their behavior. For instance, a noticeable dip in the reflectance curve might signal the presence of a specific type of vegetation. These distinct features on the <strong>spectral profiles</strong> allow researchers to develop <strong>indices</strong> that are commonly employed for image interpretation.</p>
<p><img alt="Spectral Indice Example 2" src="https://raw.githubusercontent.com/eo-agh/eo-course/main/docs/assets/images/lecture2_image12.png" /><br />
Source: Ma, M., et al. (2007) Change in area of Ebinur Lake during the 1998–2005 period. International Journal of Remote Sensing, 28(24), 5523-5533.</p>
<h2 id="21-deep-dive-into-spectral-indices">2.1 Deep dive into Spectral Indices</h2>
<p>In the following material, the Spectral Indice's formula use letter symbols to represent the reflectance values in specific spectral channels - for example, R represents the reflectance in the red channel, while NIR denotes that in the near-infrared channel, among others. These equations are general and not tied to images from any particular satellite. To calculate any given coefficient in practice, one must substitute the appropriate channel that covers the required wavelength range for the specific satellite being used. Typically, these formulas are simple algebraic expressions that have been refined over years of scientific research to highlight certain land cover types, such as vegetation, and to assess its condition.</p>
<p>Beyond their basic function, these indices - particularly the Vegetation Index (VI) and the Normalized Difference Vegetation Index (NDVI) - have become indispensable tools in the study of vegetation health. Modern remote sensing technologies have significantly improved the accuracy of reflectance measurements across various spectral bands. This progress has not only deepened our understanding of ecosystem dynamics but has also expanded the applications of these indices into fields like precision agriculture, environmental monitoring, and even urban planning. Researchers continue to innovate, adapting these traditional metrics to new satellite platforms and emerging challenges in environmental management.</p>
<h2 id="211-what-is-ndvi">2.1.1 What is NDVI?</h2>
<p>📌 <strong>Normalized Difference Vegetation Index</strong></p>
<p>– Based on the relationship between red and near-infrared wavelengths
– Chlorophyll strongly absorbs visible (red)
– Plant structure strongly reflects near-infrared</p>
<p><img alt="Spectral Indice Example 3" src="https://raw.githubusercontent.com/eo-agh/eo-course/main/docs/assets/images/lecture2_image13.png" />  </p>
<p><strong>NDVI Formula:</strong></p>
<p>$$
NDVI = \frac{NIR - R}{NIR + R}
$$</p>
<p>Where: 
- NIR means Near-Infrared
- R - Red</p>
<p><strong>Values range from -1.0 to 1.0.</strong>
– Negative values to 0 mean no green leaves.
– Values close to 1 indicate the highest possible density of green leaves.</p>
<p><img alt="Spectral Indice Example 4" src="https://raw.githubusercontent.com/eo-agh/eo-course/main/docs/assets/images/lecture2_image14.png" /></p>
<p>Source credit: Robert Simmon</p>
<p><strong>NDVI and seasonality</strong></p>
<p>Remote sensing is used to track the seasonal changes in vegetation. Monthly NDVI images from MODIS or Landsat can be used to monitor phenology.</p>
<p><img alt="Spectral Indice Example 5" src="https://raw.githubusercontent.com/eo-agh/eo-course/main/docs/assets/images/lecture2_image15.png" /></p>
<p>NDVI Images of North America in Winter and Summer. Credit: spacegrant.montana.edu</p>
<p><strong>How can we detect anomalies using NDVI?</strong></p>
<ol>
<li>Departure of NDVI from the long-term average, normalized by long-term variability</li>
<li>Generated by subtracting the long-term mean from the current value for that month of the year for each grid cell</li>
<li>Indicates if vegetation greenness at a particular location is typical for that period or if the vegetation is more or less green</li>
</ol>
<p><img alt="Spectral Indice Example 6" src="https://raw.githubusercontent.com/eo-agh/eo-course/main/docs/assets/images/lecture2_image16.png" />
NDVI Anomalies in the Southwestern United States</p>
<p><strong>NDVI Example Calculation</strong></p>
<p><img alt="Spectral Indice Example 7" src="https://raw.githubusercontent.com/eo-agh/eo-course/main/docs/assets/images/lecture2_image17.png" />
NDVI Anomalies in the Southwestern United States</p>
<p><img alt="Spectral Indice Example 8" src="https://raw.githubusercontent.com/eo-agh/eo-course/main/docs/assets/images/lecture2_image18.png" />
NDVI Anomalies in the Southwestern United States</p>
<p><img alt="Spectral Indice Example 9" src="https://raw.githubusercontent.com/eo-agh/eo-course/main/docs/assets/images/lecture2_image19.png" />
NDVI Anomalies in the Southwestern United States</p>
<h1 id="remote-sensing-indices-and-formulas">Remote Sensing Indices and Formulas</h1>
<h3 id="2-ndti-normalized-difference-turbidity-index">2. <strong>NDTI</strong> - Normalized Difference Turbidity Index</h3>
<p><strong>Formula</strong>:
$$
NDTI = \frac{R - G}{R + G}
$$
<strong>Range:</strong> from -1 to +1<br />
<strong>Description:</strong> Measures water turbidity. Higher positive values indicate higher turbidity (cloudy or sediment-rich water), while lower values suggest clearer water.</p>
<p><img alt="Spectral Indice Example 10" src="https://raw.githubusercontent.com/eo-agh/eo-course/main/docs/assets/images/lecture2_image20.png" /></p>
<p>Lizcano-Sandoval, Luis &amp; Anastasiou, Christopher &amp; Montes, Enrique &amp; Raulerson, Gary &amp; Sherwood, Edward &amp; Muller-Karger, Frank. (2022). Seagrass distribution, areal cover, and changes (1990–2021) in coastal waters off West-Central Florida, USA. Estuarine Coastal and Shelf Science. 279. 108134. 10.1016/j.ecss.2022.108134. </p>
<hr />
<h3 id="3-ndci-normalized-difference-chlorophyll-index">3. <strong>NDCI</strong> - Normalized Difference Chlorophyll Index</h3>
<p><strong>Formula</strong>:
$$
NDCI = \frac{R_{708nm} - R_{665nm}}{R_{708nm} + R_{665nm}}
$$
<strong>Range:</strong> from -1 to +1<br />
<strong>Description:</strong> Detects chlorophyll concentration in aquatic environments. Higher values indicate increased chlorophyll (algal blooms), while low values suggest low algae presence.</p>
<iframe width="560" height="315" src="https://www.youtube.com/watch?v=YKIvNWGZjfQ" title="YouTube video player" frameborder="0" allowfullscreen></iframe>

<hr />
<h3 id="4-fai-floating-algae-index">4. <strong>FAI</strong> - Floating Algae Index</h3>
<p><strong>Formula</strong>:
$$
FAI = R_{859nm} - \left( R_{645nm} + (R_{1240nm} - R_{645nm}) \times \frac{859 - 645}{1240 - 645} \right)
$$
<strong>Range:</strong> variable (negative or positive)<br />
<strong>Description:</strong> Highlights floating algae presence. Positive high values indicate floating algae blooms.</p>
<p><img alt="Spectral Indice Example 10" src="https://raw.githubusercontent.com/eo-agh/eo-course/main/docs/assets/images/lecture2_image21.png" /></p>
<p>Zhao, Dan &amp; Li, Junsheng &amp; Hu, Rongming &amp; Shen, Qian &amp; Zhang, Fangfang. (2018). Landsat-satellite-based analysis of spatial–temporal dynamics and drivers of CyanoHABs in the plateau Lake Dianchi. International Journal of Remote Sensing. 39. 1-20. 10.1080/01431161.2018.1488289. </p>
<hr />
<h3 id="5-afai-alternate-floating-algae-index">5. <strong>AFAI</strong> - Alternate Floating Algae Index</h3>
<p><strong>Formula</strong>:
$$
AFAI = R_{865nm} - \left( R_{665nm} + (R_{1610nm} - R_{665nm}) \times \frac{865 - 665}{1610 - 665} \right)
$$
<strong>Range:</strong> variable (negative or positive)<br />
<strong>Description:</strong> Similar to FAI, identifies floating algae on water surfaces. Positive values strongly indicate algae presence.</p>
<p><img alt="Spectral Indice Example 11" src="https://raw.githubusercontent.com/eo-agh/eo-course/main/docs/assets/images/lecture2_image22.png" /></p>
<p>Descloitres, Jacques &amp; Minghelli, Audrey &amp; Steinmetz, François &amp; Chevalier, Cristèle &amp; Chami, Malik &amp; Berline, Leo. (2021). Revisited Estimation of Moderate Resolution Sargassum Fractional Coverage Using Decametric Satellite Data (S2-MSI). Remote Sensing. 13. 5106. 10.3390/rs13245106. </p>
<hr />
<h3 id="6-evi-enhanced-vegetation-index">6. <strong>EVI</strong> - Enhanced Vegetation Index</h3>
<p><strong>Formula</strong>:
$$
EVI = 2.5 \times \frac{NIR - R}{NIR + 6 \times R - 7.5 \times B + 1}
$$
<strong>Range:</strong> typically from -1 to +1<br />
<strong>Description:</strong> Sensitive to dense vegetation and less affected by atmospheric conditions compared to NDVI. High values reflect dense, healthy vegetation.</p>
<p><img alt="Spectral Indice Example 12" src="https://raw.githubusercontent.com/eo-agh/eo-course/main/docs/assets/images/lecture2_image23.png" />
EVI, Italy. Acquired on 08.10.2017, processed by Sentinel Hub. Source: https://custom-scripts.sentinel-hub.com/custom-scripts/sentinel-2/evi/ </p>
<hr />
<h3 id="7-savi-soil-adjusted-vegetation-index">7. <strong>SAVI</strong> - Soil-Adjusted Vegetation Index</h3>
<p><strong>Formula</strong>:
$$
SAVI = \frac{(NIR - R) \times (1 + L)}{NIR + R + L}
$$
where typically (L=0.5).</p>
<p><strong>Range:</strong> from -1 to +1<br />
<strong>Description:</strong> Minimizes soil background effects, ideal for vegetation monitoring in sparse or semi-arid regions. Higher values represent healthier vegetation.
<img alt="Spectral Indice Example 13" src="https://raw.githubusercontent.com/eo-agh/eo-course/main/docs/assets/images/lecture2_image24.png" />
SAVI visualized image, Italy. Acquired on 25.05.2020, processed by Sentinel Hub. Source: https://custom-scripts.sentinel-hub.com/custom-scripts/sentinel-2/savi/</p>
<hr />
<h3 id="8-nbr-normalized-burn-ratio">8. <strong>NBR</strong> - Normalized Burn Ratio</h3>
<p><strong>Formula</strong>:
$$
NBR = \frac{NIR - SWIR}{NIR + SWIR}
$$
<strong>Range:</strong> from -1 to +1<br />
<strong>Description:</strong> Used to assess burned areas and vegetation recovery post-fire. Lower or negative values indicate burned areas; higher positive values suggest healthy vegetation.</p>
<p><img alt="Spectral Indice Example 14" src="https://raw.githubusercontent.com/eo-agh/eo-course/main/docs/assets/images/lecture2_image25.png" />
This image displays a (left) Landsat Surface Reflectance (SR) and (right) the SR-derived Landsat Surface Reflectance Normalized Burn Ratio (NBR). Source: www.usgs.gov</p>
<h2 id="3-land-useland-cover-classification-lulc">3. Land Use/Land Cover Classification (LULC)</h2>
<p><strong>What is Land Cover Classification?</strong></p>
<p>Land cover classification is the process of assigning each pixel in a satellite image to a specific class, based on its characteristics. Typically, classification is done by comparing spectral reflectance patterns across different land-use categories. The result is a thematic map illustrating different land cover types.</p>
<p><strong>Example classification map:</strong></p>
<p><img alt="LULC 1" src="https://raw.githubusercontent.com/eo-agh/eo-course/main/docs/assets/images/lecture2_image26.png" /></p>
<p><em>Source: <a href="https://natural-resources.canada.ca/maps-tools-publications/satellite-elevation-air-photos/image-classification-analysis">Natural Resources Canada</a></em></p>
<hr />
<h2 id="two-main-methods-of-land-cover-classification">🎯 <strong>Two Main Methods of Land Cover Classification</strong></h2>
<h3 id="1-supervised-classification">1. <strong>Supervised Classification</strong></h3>
<p>In supervised classification, the user selects example areas (known as training sites), each representing specific land cover classes. The algorithm analyzes the statistical properties of these samples to classify the entire image.</p>
<p><strong>Common Algorithms:</strong>
- Maximum Likelihood
- Minimum Distance
- Random Forest (RF)
- Support Vector Machine (SVM)</p>
<p><strong>Supervised Classification example:</strong></p>
<p><img alt="LULC 2" src="https://raw.githubusercontent.com/eo-agh/eo-course/main/docs/assets/images/lecture2_image27.png" /></p>
<p><em>Source: <a href="https://natural-resources.canada.ca/maps-tools-publications/satellite-elevation-air-photos/image-classification-analysis">Natural Resources Canada</a></em></p>
<hr />
<h3 id="2-unsupervised-classification">2. <strong>Unsupervised Classification</strong></h3>
<p>In unsupervised classification, the algorithm automatically groups pixels with similar spectral properties into clusters. After the algorithm generates these clusters, the user interprets them and assigns appropriate land cover classes.</p>
<p><strong>Common Algorithms:</strong>
- K-means
- ISODATA</p>
<p><strong>Unsupervised Classification example:</strong></p>
<p><img alt="LULC 3" src="https://raw.githubusercontent.com/eo-agh/eo-course/main/docs/assets/images/lecture2_image28.png" /></p>
<p><em>Source: <a href="https://natural-resources.canada.ca/maps-tools-publications/satellite-elevation-air-photos/image-classification-analysis">Natural Resources Canada</a></em></p>
<hr />
<h2 id="accuracy-assessment">📊 <strong>Accuracy Assessment</strong></h2>
<p>The accuracy of classification maps is evaluated through confusion matrices, which include metrics such as:</p>
<ul>
<li><strong>Overall Accuracy (OA)</strong>: Percentage of correctly classified pixels.</li>
<li><strong>Producer’s Accuracy (PA)</strong>: Accuracy from the perspective of the map producer (precision).</li>
<li><strong>User’s Accuracy (UA)</strong>: Reliability from the user’s perspective.</li>
<li><strong>Kappa Coefficient</strong>: Measures agreement between the classification and ground-truth data.</li>
</ul>
<hr />
<h2 id="applications">🛰️ <strong>Applications</strong></h2>
<p>Land cover classification is useful for:</p>
<ul>
<li>Detecting and analyzing land cover changes</li>
<li>Environmental monitoring</li>
<li>Analyzing urbanization and impermeable surfaces</li>
<li>Agricultural mapping and crop classification</li>
</ul>












                
              </article>
            </div>
          
          
<script>var target=document.getElementById(location.hash.slice(1));target&&target.name&&(target.checked=target.name.startsWith("__tabbed_"))</script>
        </div>
        
      </main>
      
        <footer class="md-footer">
  
  <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">
      <div class="md-copyright">
  
    <div class="md-copyright__highlight">
      Copyright 2025 AGH UST
    </div>
  
  
    Made with
    <a href="https://squidfunk.github.io/mkdocs-material/" target="_blank" rel="noopener">
      Material for MkDocs
    </a>
  
</div>
      
    </div>
  </div>
</footer>
      
    </div>
    <div class="md-dialog" data-md-component="dialog">
      <div class="md-dialog__inner md-typeset"></div>
    </div>
    
    
    
      
      <script id="__config" type="application/json">{"base": "../../..", "features": [], "search": "../../javascripts/workers/search.f8cc74c7.min.js", "tags": null, "translations": {"clipboard.copied": "Copied to clipboard", "clipboard.copy": "Copy to clipboard", "search.result.more.one": "1 more on this page", "search.result.more.other": "# more on this page", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents", "search.result.placeholder": "Type to start searching", "search.result.term.missing": "Missing", "select.version": "Select version"}, "version": null}</script>
    
    
      <script src="../../javascripts/bundle.c8b220af.min.js"></script>
      
    
  </body>
</html>